# Fazit

Code Llama zeigt eine eher gemischte Leistung.
Es ist in Anbetracht dessen,
dass es "open-source" ist, ein durchaus brauchbares Tool für den persönlichen Gebrauch in einer lokalen Umgebung, für z.B. Nutzer, die Wert auf Datenschutz legen, da es in der Sicht kaum bekannte Alternativen
gibt. Jedoch sind die Ergebnisse, oft mit Fehlern
behaftet und auch bei einfacheren Forderungen scheitert Code Llama.
Daher ist bei diesem Sprachmodell besondere
Vorsicht geboten, den Ergebnissen glauben zu schenken.
Hat man die Möglichkeit z.B. GPT-3.5 oder GPT-4 zu nutzen, ist dies auf jeden Fall eine vorzuziehende
Lösung.

## Ist Code Llama open source?

Man den sollte den Begriff open-source in Kontext
von Code Llama auch mit Vorsicht genießen,
denn Llama 2 und somit auch Code LLama ist unter
einer eigenen Softwarelizenz von Meta lizenziert, welche nicht von der Open Source Initiative akzeptiert.
Diese Lizenz bringt folgende Restriktionen mit sich:

1. _You will not use the Llama Materials or any output or results of the
   Llama Materials to improve any other large language model (excluding Llama 2 or
   derivative works thereof)._

2. _Additional Commercial Terms. If, on the Llama 2 version release date, the
   monthly active users of the products or services made available by or for Licensee,
   or Licensee's affiliates, is greater than 700 million monthly active users in the
   preceding calendar month, you must request a license from Meta, which Meta may
   grant to you in its sole discretion, and you are not authorized to exercise any of the
   rights under this Agreement unless or until Meta otherwise expressly grants you
   such rights._

**Update vom 27.12**:

Es gibt mittlerweile
eine 70B-Version von Code Llama, die am 29.01.2024
veröffentlicht worden ist. Sie ist auch wieder in den
drei bekannten verschiedenen Varianten verfügbar.
Mit dieser Version, könnten die Ergebnisse besser
sein, als die, die in diesem Test genutzte 34B-Version.

Laut Meta übertrifft die Leistung von Code Llama
anderen öffentlich verfügbaren LLMs in Benchmark-Tests
[@IntroducingCodeLlama2023]

\newpage \setlength\parindent{0pt}

# Referenzen
